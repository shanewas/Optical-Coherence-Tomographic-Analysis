{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"res_potato.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZObod_LQzs90","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import PIL\n","import tensorflow as tf\n","import numpy as np\n","import os\n","\n","from tensorflow.python.keras.models import Model, Sequential\n","from tensorflow.python.keras.layers import Dense, Flatten, Dropout\n","# from tensorflow.python.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.python.keras.applications.resnet50 import ResNet50\n","from tensorflow.python.keras.applications.inception_v3 import preprocess_input, decode_predictions\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.keras.optimizers import Adam, RMSprop\n","\n","train_dir = \"/content/drive/My Drive/ADNI_C/test/des/ADtrain\"\n","test_dir = \"/content/drive/My Drive/ADNI_C/test/des/ADtest\"\n","\n","model = ResNet50(include_top=False,input_shape=(224, 224, 3), weights='imagenet')\n","input_shape = (224,224)\n","\n","datagen_train = ImageDataGenerator(rescale=1./255)\n","datagen_test = ImageDataGenerator(rescale=1./255)\n","\n","\n","batch_size = 20\n","\n","\n","generator_train = datagen_train.flow_from_directory(directory=train_dir,\n","                                                    target_size=input_shape,\n","                                                    batch_size=batch_size,nafizahmednafi\n","                                                    shuffle=True)\n","\n","generator_test = datagen_test.flow_from_directory(directory=test_dir,nafizahmednafi\n","                                                  target_size=input_shape,\n","                                                  batch_size=batch_size,\n","                                                  shuffle=False)\n","\n","steps_test = generator_test.n / batch_size\n","\n","\n","def path_join(dirname, filenames):\n","    return [os.path.join(dirname, filename) for filename in filenames]\n","\n","image_paths_train = path_join(train_dir, generator_train.filenames)\n","image_paths_test = path_join(test_dir, generator_test.filenames)\n","\n","cls_train = generator_train.classes\n","cls_test = generator_test.classes\n","\n","\n","class_names = list(generator_train.class_indices.keys())\n","num_classes = generator_train.num_classes\n","\n","transfer_layer = model.get_layer('add_15')\n","conv_model = Model(inputs=model.input, outputs=transfer_layer.output)\n","\n","#for layer in conv_model.layers:\n","#    layer.trainable = False\n","    \n","# Start a new Keras Sequential model.\n","new_model = Sequential()\n","\n","# Add the convolutional part of the VGG16 model from above.\n","new_model.add(conv_model)\n","\n","# Flatten the output of the VGG16 model because it is from a\n","# convolutional layer.\n","new_model.add(Flatten())\n","\n","# Add a dense (aka. fully-connected) layer.\n","# This is for combining features that the VGG16 model has\n","# recognized in the image.\n","new_model.add(Dropout(0.5))\n","\n","new_model.add(Dense(1024, activation='relu'))\n","\n","# Add a dropout-layer which may prevent overfitting and\n","# improve generalization ability to unseen data e.g. the test-set.\n","#new_model.add(Dense(512, activation='relu'))\n","\n","\n","# Add the final layer for the actual classification.\n","new_model.add(Dense(num_classes, activation='softmax'))\n","\n","optimizer = Adam(lr=1e-5)\n","loss = 'categorical_crossentropy'\n","metrics = ['categorical_accuracy']\n","\n","\n","def print_layer_trainable():\n","    for layer in conv_model.layers:\n","        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))\n","\n","\n","print_layer_trainable()\n","\n","new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","epochs = 15\n","steps_per_epoch = 100\n","\n","\n","history = new_model.fit_generator(generator=generator_train,\n","                                  epochs=epochs,\n","                                  steps_per_epoch=steps_per_epoch,\n","                                  validation_data=generator_test,\n","                                  validation_steps=steps_test)\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SWdJS-kRlHhN","colab_type":"code","outputId":"a7285c22-500a-497a-eef6-6741f5d92081","executionInfo":{"status":"ok","timestamp":1570343494007,"user_tz":-360,"elapsed":34356,"user":{"displayName":"SHANEWAS AHMED NABIL","photoUrl":"","userId":"17864818584441031388"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]}]}