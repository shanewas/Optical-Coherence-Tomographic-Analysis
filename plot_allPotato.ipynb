{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"plot_allPotato.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"yEV6M7rv5rlk","colab_type":"code","outputId":"d5332bf6-d897-4bdd-b03d-7d7589810498","colab":{"base_uri":"https://localhost:8080/","height":581}},"source":["import matplotlib.pyplot as plt\n","import PIL\n","import tensorflow as tf\n","import numpy as np\n","import os\n","\n","from tensorflow.python.keras.models import Model, Sequential\n","from tensorflow.python.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.python.keras.applications.vgg19 import VGG19\n","from tensorflow.python.keras.applications.inception_v3 import preprocess_input, decode_predictions\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.keras.optimizers import Adam, RMSprop\n","\n","train_dir = \"/content/drive/My Drive/ADNI_C/test/des/ADtrain\"\n","test_dir = \"/content/drive/My Drive/ADNI_C/test/des/ADtest\"\n","\n","model = VGG19(include_top=False,input_shape=(224, 224, 3), weights='imagenet')\n","input_shape = (224,224)\n","\n","datagen_train = ImageDataGenerator(rescale=1./255)\n","datagen_test = ImageDataGenerator(rescale=1./255)\n","\n","\n","batch_size = 20\n","\n","generator_train = datagen_train.flow_from_directory(directory=train_dir,\n","                                                    target_size=input_shape,\n","                                                    batch_size=batch_size,\n","                                                    shuffle=True)\n","\n","generator_test = datagen_test.flow_from_directory(directory=test_dir,\n","                                                  target_size=input_shape,\n","                                                  batch_size=batch_size,\n","                                                  shuffle=False)\n","\n","steps_test = generator_test.n / batch_size\n","\n","\n","def path_join(dirname, filenames):\n","    return [os.path.join(dirname, filename) for filename in filenames]\n","\n","image_paths_train = path_join(train_dir, generator_train.filenames)\n","image_paths_test = path_join(test_dir, generator_test.filenames)\n","\n","cls_train = generator_train.classes\n","cls_test = generator_test.classes\n","\n","\n","class_names = list(generator_train.class_indices.keys())\n","num_classes = generator_train.num_classes\n","\n","transfer_layer = model.get_layer('block5_pool')\n","conv_model = Model(inputs=model.input, outputs=transfer_layer.output)\n","\n","#for layer in conv_model.layers:\n","#    layer.trainable = False\n","    \n","# Start a new Keras Sequential model.\n","new_model = Sequential()\n","\n","# Add the convolutional part of the VGG16 model from above.\n","new_model.add(conv_model)\n","\n","# Flatten the output of the VGG16 model because it is from a\n","# convolutional layer.\n","new_model.add(Flatten())\n","\n","# Add a dense (aka. fully-connected) layer.\n","# This is for combining features that the VGG16 model has\n","# recognized in the image.\n","new_model.add(Dropout(0.5))\n","\n","new_model.add(Dense(1024, activation='relu'))\n","\n","# Add a dropout-layer which may prevent overfitting and\n","# improve generalization ability to unseen data e.g. the test-set.\n","#new_model.add(Dense(512, activation='relu'))\n","\n","\n","# Add the final layer for the actual classification.\n","new_model.add(Dense(num_classes, activation='softmax'))\n","\n","optimizer = Adam(lr=1e-5)\n","loss = 'categorical_crossentropy'\n","metrics = ['categorical_accuracy']\n","\n","\n","def print_layer_trainable():\n","    for layer in conv_model.layers:\n","        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))\n","\n","\n","print_layer_trainable()\n","\n","new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","epochs = 5\n","steps_per_epoch = 100\n","\n","\n","history = new_model.fit_generator(generator=generator_train,\n","                                  epochs=epochs,\n","                                  steps_per_epoch=steps_per_epoch,\n","                                  validation_data=generator_test,\n","                                  validation_steps=steps_test)\n"," "],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0804 09:13:07.050271 140598261315456 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 1s 0us/step\n","Found 11192 images belonging to 3 classes.\n","Found 2798 images belonging to 3 classes.\n","True:\tinput_1\n","True:\tblock1_conv1\n","True:\tblock1_conv2\n","True:\tblock1_pool\n","True:\tblock2_conv1\n","True:\tblock2_conv2\n","True:\tblock2_pool\n","True:\tblock3_conv1\n","True:\tblock3_conv2\n","True:\tblock3_conv3\n","True:\tblock3_conv4\n","True:\tblock3_pool\n","True:\tblock4_conv1\n","True:\tblock4_conv2\n","True:\tblock4_conv3\n","True:\tblock4_conv4\n","True:\tblock4_pool\n","True:\tblock5_conv1\n","True:\tblock5_conv2\n","True:\tblock5_conv3\n","True:\tblock5_conv4\n","True:\tblock5_pool\n","Epoch 1/5\n"," 99/100 [============================>.] - ETA: 51s - loss: 1.1716 - categorical_accuracy: 0.4010 "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bfUUcy2O5xOI","colab_type":"code","colab":{}},"source":["def plot_training_history(history):\n","    # Get the classification accuracy and loss-value\n","    # for the training-set.\n","    acc = history.history['categorical_accuracy']\n","    loss = history.history['loss']\n","\n","    # Get it for the validation-set (we only use the test-set).\n","    val_acc = history.history['val_categorical_accuracy']\n","    val_loss = history.history['val_loss']\n","\n","    # Plot the accuracy and loss-values for the training-set.\n","    plt.plot(acc, linestyle='-', color='b', label='Training Acc.')\n","    plt.plot(loss, 'o', color='b', label='Training Loss')\n","    \n","    # Plot it for the test-set.\n","    plt.plot(val_acc, linestyle='--', color='r', label='Test Acc.')\n","    plt.plot(val_loss, 'o', color='r', label='Test Loss')\n","\n","    # Plot title and legend.\n","    plt.title('Training and Test Accuracy')\n","    plt.legend()\n","\n","    # Ensure the plot shows correctly.\n","    plt.show()\n","\n","\n","plot_training_history(history)"],"execution_count":0,"outputs":[]}]}